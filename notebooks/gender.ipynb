{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# read data\n",
    "DATA_PATH = \"../new_data/Train/\"\n",
    "image_data = pd.read_csv(os.path.join(DATA_PATH, \"Image\", \"oxford.csv\"))\n",
    "profile_data = pd.read_csv(os.path.join(DATA_PATH, \"Profile\", \"Profile.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training data\n",
    "1. Choose userIds whose labels are available in profile data\n",
    "1. Filter out rows from oxford data with null values\n",
    "1. Choose which face to train with for the given userId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_images = image_data[image_data.userId.isin(profile_data.userid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7915, 7915, 9500)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_data.userId.size, filtered_images.userId.size, profile_data.userid.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_empty = filtered_images.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = non_empty.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate and find columns where min, max and mean are all same\n",
    "irrelevant_columns = []\n",
    "for c in summary.columns:\n",
    "    col_stats = summary[c]\n",
    "    if col_stats['min'] == col_stats['mean'] or col_stats['max'] == col_stats['mean']:\n",
    "        irrelevant_columns.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_empty.drop(labels=irrelevant_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "id_col = ['userId', 'faceID']\n",
    "for row in profile_data.iterrows():\n",
    "    row = row[1]\n",
    "    faces = non_empty[non_empty.userId == row.userid]\n",
    "    if faces.size == 0:\n",
    "        continue\n",
    "    # randomly choose the first row\n",
    "    X.append(faces.iloc[0].drop(labels=id_col))\n",
    "    y.append(row.gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = pd.DataFrame(X_train), pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize and Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "def preprocess(df, scaler_type, scalers=None):\n",
    "    used_scalers = {}\n",
    "    ret_df = df.copy(deep=True)\n",
    "    for c in df.columns:\n",
    "        if c in ['userId', 'faceID']:\n",
    "            continue\n",
    "        if scalers is None:\n",
    "            c_scaler = scaler_type()\n",
    "            used_scalers[c] = c_scaler\n",
    "            func = c_scaler.fit_transform\n",
    "        else:\n",
    "            c_scaler = scalers[c]\n",
    "            func = c_scaler.transform\n",
    "        ret_df[c] = func(df[[c]].values.astype(float))\n",
    "    if scalers is None:\n",
    "        return ret_df, used_scalers\n",
    "    return ret_df, scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def preprocess_splits(X_train, X_test):\n",
    "    # standardize train\n",
    "    X_std_train, standard_scalers = preprocess(X_train, StandardScaler)\n",
    "    # normalize train\n",
    "    X_norm_train, norm_scalers = preprocess(X_std_train, MinMaxScaler)\n",
    "\n",
    "    # standardize test\n",
    "    X_std_test, _ = preprocess(X_test, StandardScaler, standard_scalers)\n",
    "    # normalize test\n",
    "    X_norm_test, _ = preprocess(X_std_test, MinMaxScaler, norm_scalers)\n",
    "    \n",
    "    return X_norm_train, X_norm_test\n",
    "X_norm_train, X_norm_test = preprocess_splits(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)\n",
    "pca_train_data = pca.fit_transform(X_norm_train)\n",
    "pca_test_data = pca.transform(X_norm_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def eval_model(model_cls, model_params, train_data, test_data):\n",
    "    model = model_cls(**model_params)\n",
    "\n",
    "    # fit model\n",
    "    model.fit(*train_data)\n",
    "\n",
    "    # evaluate train perf\n",
    "    train_pred = model.predict(train_data[0])\n",
    "    train_acc = accuracy_score(train_data[1], train_pred)\n",
    "\n",
    "    # test performance\n",
    "    test_pred = model.predict(test_data[0])\n",
    "    test_acc = accuracy_score(test_data[1], test_pred)\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'train_acc': train_acc,\n",
    "        'test_acc': test_acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModeModel(object):\n",
    "    def __init__(self):\n",
    "        self.ans=1\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return len(X) *[self.ans]\n",
    "    def fit_predict(self, X, y=None):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: ModeModel Train Acc 0.5996592844974447 Test Acc 0.5704323570432357\n",
      "Method: QuadraticDiscriminantAnalysis Train Acc 0.8266997057457023 Test Acc 0.8117154811715481\n",
      "Method: LogisticRegression Train Acc 0.8280935418925197 Test Acc 0.8019525801952581\n",
      "Method: LinearDiscriminantAnalysis Train Acc 0.8287130246244386 Test Acc 0.810320781032078\n",
      "Method: SVC Train Acc 0.8039337153476847 Test Acc 0.7712691771269177\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA, LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.svm import SVC\n",
    "methods = [ModeModel, QDA, LogisticRegression, LDA, SVC]\n",
    "method_params = [{}, {},{'solver': 'newton-cg'}, {}, {'gamma': 'auto'}]\n",
    "train_data = (X_norm_train, y_train)\n",
    "test_data = (X_norm_test, y_test)\n",
    "for m, m_params in zip(methods, method_params):\n",
    "    ret = eval_model(m, m_params, train_data, test_data)\n",
    "    print('Method: {} Train Acc {} Test Acc {}'.format(m.__name__, ret['train_acc'], ret['test_acc']))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "kf = KFold(n_splits=10)\n",
    "method_stats = {}\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = pd.DataFrame(X[train_index]), pd.DataFrame(X[test_index])\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    X_train, X_test = preprocess_splits(X_train, X_test)\n",
    "\n",
    "    train_data = (X_train, y_train)\n",
    "    test_data = (X_test, y_test)\n",
    "    for m, m_params in zip(methods, method_params):\n",
    "        ret = eval_model(m, m_params, train_data, test_data)\n",
    "        m_name = m.__name__\n",
    "        if m_name not in method_stats:\n",
    "            method_stats[m_name] = []\n",
    "        method_stats[m_name].append([ret['train_acc'], ret['test_acc']])\n",
    "for m_name, stats in method_stats.items():\n",
    "    stats = np.array(stats)\n",
    "    mean = np.mean(stats, axis=1)\n",
    "    std = np.std(stats, axis=1)\n",
    "    print('Method: {} Train Acc {}+={} Test Acc {}+={}'.format(m_name, mean[0], std[0], mean[1], std[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
